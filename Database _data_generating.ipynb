{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cinema Data Generation and Fixes\n",
    "\n",
    "This notebook generates synthetic data for a cinema management system, backfills missing transactions, and fixes missing ticket associations. The data is stored in a PostgreSQL database.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Database Configuration](#database-configuration)\n",
    "2. [Data Generation](#data-generation)\n",
    "   - [Populate Static Dimensions](#populate-static-dimensions)\n",
    "   - [Generate Customers](#generate-customers)\n",
    "   - [Generate Time Dimension](#generate-time-dimension)\n",
    "   - [Generate Movies and Relations](#generate-movies-and-relations)\n",
    "   - [Generate Showings and Tickets](#generate-showings-and-tickets)\n",
    "   - [Generate Transactions](#generate-transactions)\n",
    "3. [Backfill Missing Transactions](#backfill-missing-transactions)\n",
    "4. [Fix Missing Tickets](#fix-missing-tickets)\n",
    "\n",
    "\n",
    "---\n",
    "## Database Configuration\n",
    "\n",
    "The database connection details are stored in environment variables. Replace the placeholders with your actual database credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary==2.9.9 (from -r requirements.txt (line 1))\n",
      "  Downloading psycopg2_binary-2.9.9-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Collecting Faker==19.13.0 (from -r requirements.txt (line 2))\n",
      "  Downloading Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 3))\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from Faker==19.13.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.4->Faker==19.13.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Downloading psycopg2_binary-2.9.9-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, psycopg2-binary, Faker\n",
      "Successfully installed Faker-19.13.0 psycopg2-binary-2.9.9 python-dotenv-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "import random\n",
    "from faker import Faker\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from io import StringIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"options\": f\"-c search_path={os.getenv('DB_SCHEMA')},public\"\n",
    "}\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Returns a connection to the PostgreSQL database.\"\"\"\n",
    "    return psycopg2.connect(**DB_CONFIG)\n",
    "\n",
    "\n",
    "NUM_CUSTOMERS = 10_000\n",
    "NUM_TRANSACTIONS = 1_000_000\n",
    "BATCH_SIZE = 10_000\n",
    "fake=Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "This section generates synthetic data for all tables in the `al_sinama` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generation...\n",
      "Data generation complete!\n"
     ]
    }
   ],
   "source": [
    "def create_tables():\n",
    "    \"\"\"Create tables if they don't exist (omitted for brevity)\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def populate_static_dimensions():\n",
    "    \"\"\"Populate static dimensions (Genres, Promotions)\"\"\"\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Genres\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_genre\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                genres = ['Action', 'Drama', 'Comedy', 'Horror', 'Sci-Fi']\n",
    "                execute_values(\n",
    "                    cursor,\n",
    "                    \"INSERT INTO dim_genre (name) VALUES %s\",\n",
    "                    [(g,) for g in genres]\n",
    "                )\n",
    "            \n",
    "            # Promotions\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_promotion\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                promotions = [\n",
    "                    (f\"Promo {i}\", random.randint(5, 30), \n",
    "                     fake.date_between('-2y'), fake.date_between('-1y'))\n",
    "                    for i in range(10)\n",
    "                ]\n",
    "                execute_values(\n",
    "                    cursor,\n",
    "                    \"\"\"INSERT INTO dim_promotion \n",
    "                       (description, discount, start_date, end_date)\n",
    "                       VALUES %s\"\"\",\n",
    "                    promotions\n",
    "                )\n",
    "            conn.commit()\n",
    "\n",
    "def generate_customers():\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_customer\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(\"Generating customers...\")\n",
    "                customers = [\n",
    "                    (fake.name(), \n",
    "                     fake.date_of_birth(minimum_age=12, maximum_age=90),\n",
    "                     random.choice(['M', 'F', 'Other']),\n",
    "                     fake.address())\n",
    "                    for _ in range(NUM_CUSTOMERS)\n",
    "                ]\n",
    "                \n",
    "                # Use COPY for bulk insert\n",
    "                buffer = StringIO()\n",
    "                for c in customers:\n",
    "                    buffer.write(\"\\t\".join([\n",
    "                        str(c[0]), str(c[1]), c[2], c[3], \"\\n\"\n",
    "                    ]))\n",
    "                buffer.seek(0)\n",
    "                \n",
    "                cursor.copy_from(\n",
    "                    buffer,\n",
    "                    \"dim_customer\",\n",
    "                    columns=(\"name\", \"dob\", \"gender\", \"address\"),\n",
    "                    null=\"\"\n",
    "                )\n",
    "                conn.commit()\n",
    "\n",
    "def generate_time_dimension():\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_time\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(\"Generating time dimension...\")\n",
    "                start_date = datetime(2014, 1, 1)\n",
    "                end_date = datetime(2024, 12, 31)\n",
    "                delta = timedelta(days=1)\n",
    "                \n",
    "                buffer = StringIO()\n",
    "                current_date = start_date\n",
    "                while current_date <= end_date:\n",
    "                    buffer.write(\"\\t\".join([\n",
    "                        str(current_date.date()),\n",
    "                        str(current_date.year),\n",
    "                        str(current_date.month),\n",
    "                        str(current_date.day),\n",
    "                        str((current_date.month - 1) // 3 + 1),\n",
    "                        str(current_date.isocalendar()[1]),\n",
    "                        \"\\n\"\n",
    "                    ]))\n",
    "                    current_date += delta\n",
    "                \n",
    "                buffer.seek(0)\n",
    "                cursor.copy_from(\n",
    "                    buffer,\n",
    "                    \"dim_time\",\n",
    "                    columns=(\"date\", \"year\", \"month\", \"day\", \"quarter\", \"week_number\")\n",
    "                )\n",
    "                conn.commit()\n",
    "\n",
    "def generate_movies_and_relations():\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Generate movies\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_movie\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(\"Generating movies...\")\n",
    "                cursor.execute(\"SELECT genre_id FROM dim_genre\")\n",
    "                genre_ids = [row[0] for row in cursor.fetchall()]\n",
    "                \n",
    "                movies = [\n",
    "                    (fake.catch_phrase(),\n",
    "                     fake.date_between('-10y'),\n",
    "                     random.choice(['English', 'Arabic', 'French']),\n",
    "                     round(random.uniform(1e6, 100e6), 2),\n",
    "                     fake.country(),\n",
    "                     random.choice(genre_ids))\n",
    "                    for _ in range(500)\n",
    "                ]\n",
    "                execute_values(\n",
    "                    cursor,\n",
    "                    \"\"\"INSERT INTO dim_movie \n",
    "                       (title, release_date, language, cost, country, genre_id)\n",
    "                       VALUES %s\"\"\",\n",
    "                    movies\n",
    "                )\n",
    "                conn.commit()\n",
    "\n",
    "            # Generate movie-star relations\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_movie_star\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(\"Generating movie-star relations...\")\n",
    "                cursor.execute(\"SELECT movie_id FROM dim_movie\")\n",
    "                movie_ids = [row[0] for row in cursor.fetchall()]\n",
    "                cursor.execute(\"SELECT star_id FROM dim_star\")\n",
    "                star_ids = [row[0] for row in cursor.fetchall()]\n",
    "                \n",
    "                relations = set()\n",
    "                while len(relations) < 2000:\n",
    "                    relations.add((\n",
    "                        random.choice(movie_ids),\n",
    "                        random.choice(star_ids)\n",
    "                    ))\n",
    "                \n",
    "                execute_values(\n",
    "                    cursor,\n",
    "                    \"INSERT INTO dim_movie_star (movie_id, star_id) VALUES %s\",\n",
    "                    list(relations)\n",
    "                )\n",
    "                conn.commit()\n",
    "\n",
    "def generate_showings_tickets(args):\n",
    "    \"\"\"Parallel ticket generation worker\"\"\"\n",
    "    show_id, hall_size = args\n",
    "    return [\n",
    "        (show_id, 1, seat_num, round(random.uniform(5, 25), 2))\n",
    "        for seat_num in range(1, hall_size + 1)\n",
    "    ]\n",
    "\n",
    "def generate_showings_and_tickets():\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Generate showings\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM dim_showing\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(\"Generating showings...\")\n",
    "                cursor.execute(\"SELECT movie_id FROM dim_movie\")\n",
    "                movie_ids = [row[0] for row in cursor.fetchall()]\n",
    "                cursor.execute(\"SELECT hall_id, size FROM dim_hall\")\n",
    "                hall_data = cursor.fetchall()\n",
    "                \n",
    "                showings = []\n",
    "                for _ in range(20000):\n",
    "                    show_date = fake.date_between_dates(\n",
    "                        datetime(2014, 1, 1), datetime(2024, 12, 31))\n",
    "                    show_time = fake.time_object()\n",
    "                    hall_id, hall_size = random.choice(hall_data)\n",
    "                    showings.append((\n",
    "                        random.choice(movie_ids),\n",
    "                        hall_id,\n",
    "                        show_date,\n",
    "                        show_time.strftime(\"%H:%M:%S\"),\n",
    "                        show_date.weekday() >= 5,\n",
    "                        'Morning' if show_time.hour < 12 else \n",
    "                        'Afternoon' if show_time.hour < 17 else 'Evening'\n",
    "                    ))\n",
    "                \n",
    "                execute_values(\n",
    "                    cursor,\n",
    "                    \"\"\"INSERT INTO dim_showing \n",
    "                       (movie_id, hall_id, date, time, is_weekend, time_of_day)\n",
    "                       VALUES %s RETURNING show_id, hall_id\"\"\",\n",
    "                    showings,\n",
    "                    page_size=1000\n",
    "                )\n",
    "                show_hall = cursor.fetchall()\n",
    "                conn.commit()\n",
    "\n",
    "                # Generate tickets in parallel\n",
    "                print(\"Generating tickets...\")\n",
    "                with Pool(cpu_count()) as pool:\n",
    "                    tickets = pool.map(\n",
    "                        generate_showings_tickets,\n",
    "                        [(s[0], next(h[1] for h in hall_data if h[0] == s[1])) \n",
    "                         for s in show_hall]\n",
    "                    )\n",
    "                \n",
    "                # Flatten results\n",
    "                tickets = [t for sublist in tickets for t in sublist]\n",
    "                \n",
    "                # Use COPY for tickets\n",
    "                buffer = StringIO()\n",
    "                for t in tickets:\n",
    "                    buffer.write(\"\\t\".join(map(str, t)) )\n",
    "                    buffer.write(\"\\n\")\n",
    "                buffer.seek(0)\n",
    "                \n",
    "                cursor.copy_from(\n",
    "                    buffer,\n",
    "                    \"dim_ticket\",\n",
    "                    columns=(\"show_id\", \"row_num\", \"seat_num\", \"price\")\n",
    "                )\n",
    "                conn.commit()\n",
    "\n",
    "def generate_transactions():\n",
    "    \"\"\"Generate and insert transaction data.\"\"\"\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Check if transactions already exist\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM fact_transaction\")\n",
    "            if cursor.fetchone()[0] == 0:\n",
    "                print(\"Generating transactions...\")\n",
    "                \n",
    "                # Pre-load lookup data\n",
    "                print(\"Loading lookup data...\")\n",
    "                # Time dimension\n",
    "                cursor.execute(\"SELECT date, time_id FROM dim_time\")\n",
    "                date_to_time = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "                \n",
    "                # Customers\n",
    "                cursor.execute(\"SELECT customer_id, dob FROM dim_customer\")\n",
    "                customers = cursor.fetchall()\n",
    "                \n",
    "                # Tickets\n",
    "                cursor.execute(\"SELECT ticket_id, price FROM dim_ticket\")\n",
    "                tickets = cursor.fetchall()\n",
    "                ticket_map = {t[0]: t[1] for t in tickets}\n",
    "                ticket_ids = list(ticket_map.keys())\n",
    "                \n",
    "                # Promotions\n",
    "                cursor.execute(\"SELECT promotion_id FROM dim_promotion\")\n",
    "                promotions = [row[0] for row in cursor.fetchall()]\n",
    "                \n",
    "                # Cinemas\n",
    "                cursor.execute(\"SELECT cinema_id FROM dim_cinema\")\n",
    "                cinema_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "                # Generate in batches\n",
    "                for batch_start in range(0, NUM_TRANSACTIONS, BATCH_SIZE):\n",
    "                    start_time = time.time()\n",
    "                    batch_size = min(BATCH_SIZE, NUM_TRANSACTIONS - batch_start)\n",
    "                    \n",
    "                    # Generate transaction data\n",
    "                    transactions = []\n",
    "                    trans_tickets = []\n",
    "                    online_trans = []\n",
    "                    offline_trans = []\n",
    "                    \n",
    "                    for _ in range(batch_size):\n",
    "                        # Random customer\n",
    "                        customer_id, dob = random.choice(customers)\n",
    "                        \n",
    "                        # Random date\n",
    "                        trans_date = fake.date_time_between_dates(\n",
    "                            datetime(2014, 1, 1), datetime(2024, 12, 31))\n",
    "                        time_id = date_to_time.get(trans_date.date())\n",
    "                        \n",
    "                        # Random tickets\n",
    "                        num_tickets = random.randint(1, 5)\n",
    "                        selected_tickets = random.sample(ticket_ids, num_tickets)\n",
    "                        total_price = sum(ticket_map[t] for t in selected_tickets)\n",
    "                        \n",
    "                        # Build transaction\n",
    "                        transactions.append((\n",
    "                            customer_id,\n",
    "                            random.choice([None] + promotions),\n",
    "                            total_price,\n",
    "                            random.choice(['Credit', 'Debit', 'Cash', 'Online']),\n",
    "                            trans_date,\n",
    "                            time_id,\n",
    "                            trans_date.year - dob.year\n",
    "                        ))\n",
    "                        \n",
    "                        # Store tickets\n",
    "                        trans_tickets.extend(selected_tickets)\n",
    "                    \n",
    "                    # Insert transactions\n",
    "                    execute_values(\n",
    "                        cursor,\n",
    "                        \"\"\"INSERT INTO fact_transaction \n",
    "                        (customer_id, promotion_id, total_price, pay_method,\n",
    "                            transaction_date, time_id, age_at_transaction)\n",
    "                        VALUES %s RETURNING transaction_id\"\"\",\n",
    "                        transactions,\n",
    "                        page_size=1000,\n",
    "                        fetch=True\n",
    "                    )\n",
    "                    trans_ids = [row[0] for row in cursor.fetchall()]\n",
    "                    \n",
    "                    # Insert tickets\n",
    "                    ticket_data = [\n",
    "                        (trans_id, ticket_id)\n",
    "                        for trans_id, ticket_id in zip(trans_ids, trans_tickets)\n",
    "                    ]\n",
    "                    execute_values(\n",
    "                        cursor,\n",
    "                        \"\"\"INSERT INTO fact_transaction_ticket\n",
    "                        (transaction_id, ticket_id) VALUES %s\"\"\",\n",
    "                        ticket_data,\n",
    "                        page_size=1000\n",
    "                    )\n",
    "                    \n",
    "                    # Split online/offline\n",
    "                    for trans_id in trans_ids:\n",
    "                        if random.random() < 0.3:\n",
    "                            online_trans.append((\n",
    "                                trans_id,\n",
    "                                random.choice(['Windows', 'MacOS', 'Linux']),\n",
    "                                random.choice(['Chrome', 'Firefox', 'Safari'])\n",
    "                            ))\n",
    "                        else:\n",
    "                            offline_trans.append((\n",
    "                                trans_id,\n",
    "                                random.choice(cinema_ids)\n",
    "                            ))\n",
    "                    \n",
    "                    # Insert online/offline\n",
    "                    if online_trans:\n",
    "                        execute_values(\n",
    "                            cursor,\n",
    "                            \"\"\"INSERT INTO fact_online_transaction\n",
    "                            (transaction_id, system_used, browser) VALUES %s\"\"\",\n",
    "                            online_trans,\n",
    "                            page_size=1000\n",
    "                        )\n",
    "                    if offline_trans:\n",
    "                        execute_values(\n",
    "                            cursor,\n",
    "                            \"\"\"INSERT INTO fact_offline_transaction\n",
    "                            (transaction_id, cinema_id) VALUES %s\"\"\",\n",
    "                            offline_trans,\n",
    "                            page_size=1000\n",
    "                        )\n",
    "                    \n",
    "                    conn.commit()\n",
    "                    elapsed = time.time() - start_time\n",
    "                    print(f\"Processed batch {batch_start//BATCH_SIZE + 1} \"\n",
    "                          f\"({batch_size} records) in {elapsed:.2f}s\")\n",
    "              \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting data generation...\")\n",
    "    \n",
    "    # Create tables if needed\n",
    "    create_tables()\n",
    "    \n",
    "    # Populate static dimensions first\n",
    "    populate_static_dimensions()\n",
    "    generate_time_dimension()\n",
    "    generate_customers()\n",
    "    generate_movies_and_relations()\n",
    "    generate_showings_and_tickets()\n",
    "    \n",
    "    # Generate transactions\n",
    "    generate_transactions()\n",
    "    \n",
    "    print(\"Data generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfill complete!\n"
     ]
    }
   ],
   "source": [
    "def backfill_missing_transactions():\n",
    "    # Get all cinema IDs for offline transactions\n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT cinema_id FROM dim_cinema\")\n",
    "            cinema_ids = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    # Batch settings\n",
    "    BATCH_SIZE = 10000\n",
    "    \n",
    "    with get_db_connection() as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Process in batches\n",
    "            offset = 0\n",
    "            while True:\n",
    "                # Fetch a batch of missing transactions\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT ft.transaction_id\n",
    "                    FROM fact_transaction ft\n",
    "                    LEFT JOIN (\n",
    "                        SELECT transaction_id FROM fact_online_transaction\n",
    "                        UNION ALL\n",
    "                        SELECT transaction_id FROM fact_offline_transaction\n",
    "                    ) AS existing ON ft.transaction_id = existing.transaction_id\n",
    "                    WHERE existing.transaction_id IS NULL\n",
    "                    LIMIT %s OFFSET %s\n",
    "                \"\"\", (BATCH_SIZE, offset))\n",
    "                batch = [row[0] for row in cursor.fetchall()]\n",
    "                \n",
    "                if not batch:\n",
    "                    break  # No more missing transactions\n",
    "                \n",
    "                # Split into online/offline (30%/70%)\n",
    "                online = []\n",
    "                offline = []\n",
    "                \n",
    "                for trans_id in batch:\n",
    "                    if random.random() < 0.3:  # 30% online\n",
    "                        online.append((\n",
    "                            trans_id,\n",
    "                            random.choice(['Windows', 'MacOS', 'Linux']),\n",
    "                            random.choice(['Chrome', 'Firefox', 'Safari'])\n",
    "                        ))\n",
    "                    else:  # 70% offline\n",
    "                        offline.append((\n",
    "                            trans_id,\n",
    "                            random.choice(cinema_ids)\n",
    "                        ))\n",
    "                \n",
    "                # Insert online transactions\n",
    "                if online:\n",
    "                    execute_values(\n",
    "                        cursor,\n",
    "                        \"\"\"INSERT INTO fact_online_transaction \n",
    "                           (transaction_id, system_used, browser) VALUES %s\"\"\",\n",
    "                        online,\n",
    "                        page_size=1000\n",
    "                    )\n",
    "                \n",
    "                # Insert offline transactions\n",
    "                if offline:\n",
    "                    execute_values(\n",
    "                        cursor,\n",
    "                        \"\"\"INSERT INTO fact_offline_transaction \n",
    "                           (transaction_id, cinema_id) VALUES %s\"\"\",\n",
    "                        offline,\n",
    "                        page_size=1000\n",
    "                    )\n",
    "                \n",
    "                conn.commit()\n",
    "                print(f\"Processed batch {offset//BATCH_SIZE + 1}\")\n",
    "                offset += BATCH_SIZE\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    backfill_missing_transactions()\n",
    "    print(\"Backfill complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3578599 ticket IDs\n",
      "Total time: 3.72 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def fix_missing_tickets_batched(batch_size=10000):\n",
    "    with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Step 1: Get all ticket IDs once\n",
    "            cursor.execute(\"SELECT ticket_id FROM dim_ticket\")\n",
    "            ticket_ids = [row[0] for row in cursor.fetchall()]\n",
    "            print(f\"Loaded {len(ticket_ids)} ticket IDs\")\n",
    "\n",
    "            # Step 2: Process in batches\n",
    "            offset = 0\n",
    "            total_fixed = 0\n",
    "            \n",
    "            while True:\n",
    "                # Fetch a batch of missing transactions\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT ft.transaction_id\n",
    "                    FROM fact_transaction ft\n",
    "                    LEFT JOIN fact_transaction_ticket ftt \n",
    "                        ON ft.transaction_id = ftt.transaction_id\n",
    "                    WHERE ftt.transaction_id IS NULL\n",
    "                    ORDER BY ft.transaction_id\n",
    "                    LIMIT %s OFFSET %s\n",
    "                \"\"\", (batch_size, offset))\n",
    "                \n",
    "                batch = [row[0] for row in cursor.fetchall()]\n",
    "                if not batch:\n",
    "                    break  # Exit loop when no more results\n",
    "                \n",
    "                # Step 3: Generate ticket associations for this batch\n",
    "                ticket_data = []\n",
    "                for trans_id in batch:\n",
    "                    num_tickets = random.randint(1, 5)\n",
    "                    selected_tickets = random.sample(ticket_ids, num_tickets)\n",
    "                    ticket_data.extend([(trans_id, tid) for tid in selected_tickets])\n",
    "                \n",
    "                # Step 4: Bulk insert for this batch\n",
    "                execute_values(\n",
    "                    cursor,\n",
    "                    \"\"\"INSERT INTO fact_transaction_ticket \n",
    "                       (transaction_id, ticket_id) VALUES %s\n",
    "                       ON CONFLICT DO NOTHING\"\"\",\n",
    "                    ticket_data,\n",
    "                    page_size=1000\n",
    "                )\n",
    "                conn.commit()\n",
    "                \n",
    "                # Step 5: Update progress\n",
    "                total_fixed += len(batch)\n",
    "                print(f\"Processed batch {offset//batch_size + 1}: \"\n",
    "                      f\"Fixed {len(batch)} transactions \"\n",
    "                      f\"(Total: {total_fixed}/~700,000)\")\n",
    "                \n",
    "                offset += batch_size\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    fix_missing_tickets_batched(batch_size=10000) \n",
    "    print(f\"Total time: {time.time()-start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
